{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Benchmarking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Back propagation benchmarking "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Raw implantations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "def sigmoid(inputVector):\n",
    "    return np.exp(inputVector)/(1+np.exp(inputVector))\n",
    "def relu(inputVector):\n",
    "    inputVector[inputVector <= 0] = 0\n",
    "    return inputVector\n",
    "def sigmoid_derivative(inputVector):\n",
    "    return inputVector*(1 - inputVector)\n",
    "def relu_derivative(inputVector):\n",
    "    inputVector[inputVector > 0] = 1\n",
    "    inputVector[inputVector <= 0] = 0\n",
    "    return inputVector\n",
    "    \n",
    "def training_func_sigmoid(LEARNING_RATE = 0.0001, epoches = 1000, print_loss = False):\n",
    "    # Raw Implentation: Sigmoid & Mean-squared\n",
    "    #32 to 32 --> sigmoid --> 32 to 8 --> sigmoid --> 8 to 1 --> 1-dimension label\n",
    "    startTime = time.time()\n",
    "    errorLog = []\n",
    "    np.random.seed(20)\n",
    "    inputSample = np.random.rand(1,32)\n",
    "    label = np.random.rand(1,1)\n",
    "    firstLayerWeight = np.random.rand(32,32)\n",
    "    firstLayerBias = np.random.rand(1,1)\n",
    "    secondLayerWeight = np.random.rand(32,8)\n",
    "    secondLayerBias = np.random.rand(1,1)\n",
    "    thirdLayerWeight = np.random.rand(8,1)\n",
    "    thirdLayerBias = np.random.rand(1,1)\n",
    "    while epoches > 0:\n",
    "        #Forward Propagation\n",
    "        firstLayerOutput_raw = np.dot(inputSample, firstLayerWeight) + firstLayerBias\n",
    "        firstLayerOutput_activation = sigmoid(firstLayerOutput_raw)\n",
    "        secondLayerOutput_raw = np.dot(firstLayerOutput_activation, secondLayerWeight) + secondLayerBias\n",
    "        secondLayerOutput_activation = sigmoid(secondLayerOutput_raw)\n",
    "        thirdLayerOutput = np.dot(secondLayerOutput_activation, thirdLayerWeight) + thirdLayerBias\n",
    "        # Error calculation\n",
    "        error = 0.5*(thirdLayerOutput - label)**2\n",
    "        # Back Propagation\n",
    "        deriativeThirdLayer = (thirdLayerOutput - label)*secondLayerOutput_activation.transpose()\n",
    "        deriativeSecondLayer = (thirdLayerOutput - label)*thirdLayerWeight.transpose()*sigmoid_derivative(secondLayerOutput_raw)*firstLayerOutput_activation.transpose()\n",
    "        deriativeFirstLayer = (thirdLayerOutput - label)*thirdLayerWeight.transpose()*sigmoid_derivative(secondLayerOutput_raw)*secondLayerWeight*(sigmoid_derivative(firstLayerOutput_raw)).transpose()\n",
    "        deriativeFirstLayer = deriativeFirstLayer.sum(axis = 1)*inputSample.transpose()\n",
    "        #Weight updates\n",
    "        firstLayerWeight = firstLayerWeight - deriativeFirstLayer*LEARNING_RATE\n",
    "        secondLayerWeight = secondLayerWeight - deriativeSecondLayer*LEARNING_RATE\n",
    "        thirdLayerWeight = thirdLayerWeight - deriativeThirdLayer*LEARNING_RATE\n",
    "        #Run epoch = 100\n",
    "        epoches -= 1\n",
    "        errorLog.append(error)\n",
    "        if print_loss == False:\n",
    "            continue\n",
    "        else:\n",
    "            print('Current Error:', error)\n",
    "    endTime = time.time()\n",
    "    print(endTime - startTime)\n",
    "    return endTime - startTime\n",
    "        \n",
    "def training_func_relu(LEARNING_RATE = 0.0001, epoches = 1000, print_loss = False):\n",
    "    # Raw Implentation: Relu & Mean-squared\n",
    "    #32 to 32 --> relu --> 32 to 8 --> relu --> 8 to 1 --> 1-dimension label\n",
    "    startTime = time.time()\n",
    "    errorLog = []\n",
    "    np.random.seed(20)\n",
    "    inputSample = np.random.rand(1,32)\n",
    "    label = np.random.rand(1,1)\n",
    "    firstLayerWeight = np.random.rand(32,32)\n",
    "    firstLayerBias = np.random.rand(1,1)\n",
    "    secondLayerWeight = np.random.rand(32,8)\n",
    "    secondLayerBias = np.random.rand(1,1)\n",
    "    thirdLayerWeight = np.random.rand(8,1)\n",
    "    thirdLayerBias = np.random.rand(1,1)\n",
    "    while epoches > 0:\n",
    "        #Forward Propagation\n",
    "        firstLayerOutput_raw = np.dot(inputSample, firstLayerWeight) + firstLayerBias\n",
    "        firstLayerOutput_activation = relu(firstLayerOutput_raw)\n",
    "        secondLayerOutput_raw = np.dot(firstLayerOutput_activation, secondLayerWeight) + secondLayerBias\n",
    "        secondLayerOutput_activation = relu(secondLayerOutput_raw)\n",
    "        thirdLayerOutput = np.dot(secondLayerOutput_activation, thirdLayerWeight) + thirdLayerBias\n",
    "        # Error calculation\n",
    "        error = 0.5*(thirdLayerOutput - label)**2\n",
    "        # Back Propagation\n",
    "        deriativeThirdLayer = (thirdLayerOutput - label)*secondLayerOutput_activation.transpose()\n",
    "        deriativeSecondLayer = (thirdLayerOutput - label)*thirdLayerWeight.transpose()*relu_derivative(secondLayerOutput_raw)*firstLayerOutput_activation.transpose()\n",
    "        deriativeFirstLayer = (thirdLayerOutput - label)*thirdLayerWeight.transpose()*relu_derivative(secondLayerOutput_raw)*secondLayerWeight*(relu_derivative(firstLayerOutput_raw)).transpose()\n",
    "        deriativeFirstLayer = deriativeFirstLayer.sum(axis = 1)*inputSample.transpose()\n",
    "        #Weight updates\n",
    "        firstLayerWeight = firstLayerWeight - deriativeFirstLayer*LEARNING_RATE\n",
    "        secondLayerWeight = secondLayerWeight - deriativeSecondLayer*LEARNING_RATE\n",
    "        thirdLayerWeight = thirdLayerWeight - deriativeThirdLayer*LEARNING_RATE\n",
    "        #Run epoch = 100\n",
    "        epoches -= 1\n",
    "        errorLog.append(error)\n",
    "        if print_loss == False:\n",
    "            continue\n",
    "        else:\n",
    "            print('Current Error:', error)\n",
    "    endTime = time.time()\n",
    "    print(endTime - startTime)\n",
    "    return endTime - startTime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.061779022216796875\n",
      "0.04342794418334961\n"
     ]
    }
   ],
   "source": [
    "time_relu = training_func_relu(epoches = 1000)\n",
    "time_sigmoid = training_func_sigmoid(epoches = 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Relu and Sigmoid test function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigmoid time: 0.0028989315032958984\n",
      "relu time: 0.001317739486694336\n"
     ]
    }
   ],
   "source": [
    "inputSamples = []\n",
    "for i in range(1000):\n",
    "    inputSamples.append(np.random.rand(1,32))\n",
    "startTime = time.time()\n",
    "for i in range(1000):\n",
    "    sigmoid(inputSamples[i-1])\n",
    "endTime = time.time()\n",
    "print('sigmoid time:', endTime - startTime)\n",
    "startTime = time.time()\n",
    "for i in range(1000):\n",
    "    relu(inputSamples[i-1])\n",
    "endTime = time.time()\n",
    "print('relu time:', endTime - startTime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigmoid time: 0.0016999244689941406\n",
      "relu time: 0.0036020278930664062\n"
     ]
    }
   ],
   "source": [
    "inputSamples = []\n",
    "for i in range(1000):\n",
    "    inputSamples.append(np.random.rand(1,32))\n",
    "startTime = time.time()\n",
    "for i in range(1000):\n",
    "    sigmoid_derivative(inputSamples[i-1])\n",
    "endTime = time.time()\n",
    "print('sigmoid time:', endTime - startTime)\n",
    "startTime = time.time()\n",
    "for i in range(1000):\n",
    "    relu_derivative(inputSamples[i-1])\n",
    "endTime = time.time()\n",
    "print('relu time:', endTime - startTime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implantation with frameworks "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pytorch using relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class testNet1(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(testNet1, self).__init__()\n",
    "        self.fc1 = nn.Linear(32, 32)\n",
    "        self.fc2 = nn.Linear(32, 8)\n",
    "        self.fc3 = nn.Linear(8, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "net = testNet1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.24171996116638184\n"
     ]
    }
   ],
   "source": [
    "#MSE loss function\n",
    "criterion = nn.MSELoss()\n",
    "# create your optimizer\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.0001)\n",
    "inputVector = torch.randn(1, 1, 1, 32)\n",
    "target = torch.randn(1, 1, 1, 1)\n",
    "startTime = time.time()\n",
    "for i in range(1000):\n",
    "    optimizer.zero_grad()   # zero the gradient buffers\n",
    "    output = net(inputVector)\n",
    "    loss = criterion(output, target)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "endTime = time.time()\n",
    "print(endTime - startTime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11628317832946777\n"
     ]
    }
   ],
   "source": [
    "startTime = time.time()\n",
    "for i in range(1000):\n",
    "    optimizer.zero_grad()   # zero the gradient buffers\n",
    "    output = net(inputVector)\n",
    "    loss = criterion(output, target)\n",
    "    #loss.backward()\n",
    "    optimizer.step()\n",
    "endTime = time.time()\n",
    "print(endTime - startTime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pytorch using sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class testNet2(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(testNet2, self).__init__()\n",
    "        self.fc1 = nn.Linear(32, 32)\n",
    "        self.fc2 = nn.Linear(32, 8)\n",
    "        self.fc3 = nn.Linear(8, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.sigmoid(self.fc1(x))\n",
    "        x = torch.sigmoid(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "net = testNet2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.24677085876464844\n"
     ]
    }
   ],
   "source": [
    "#MSE loss function\n",
    "criterion = nn.MSELoss()\n",
    "# create your optimizer\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.0001)\n",
    "inputVector = torch.randn(1, 1, 1, 32)\n",
    "target = torch.randn(1, 1, 1, 1)\n",
    "startTime = time.time()\n",
    "for i in range(1000):\n",
    "    optimizer.zero_grad()   # zero the gradient buffers\n",
    "    output = net(inputVector)\n",
    "    loss = criterion(output, target)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "endTime = time.time()\n",
    "print(endTime - startTime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11533999443054199\n"
     ]
    }
   ],
   "source": [
    "startTime = time.time()\n",
    "for i in range(1000):\n",
    "    optimizer.zero_grad()   # zero the gradient buffers\n",
    "    output = net(inputVector)\n",
    "    loss = criterion(output, target)\n",
    "    #loss.backward()\n",
    "    optimizer.step()\n",
    "endTime = time.time()\n",
    "print(endTime - startTime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "import time\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "np.random.seed(20)\n",
    "inputSample = np.random.rand(1,32)\n",
    "label = np.random.rand(1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras using relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0219383239746094\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(units=32, activation='relu', input_dim=32))\n",
    "model.add(Dense(units=8, activation='relu'))\n",
    "model.add(Dense(units=1))\n",
    "model.compile(loss=keras.losses.mean_squared_error,\n",
    "              optimizer=keras.optimizers.SGD(lr=0.01, momentum=0.9, nesterov=True))\n",
    "startTime = time.time()\n",
    "model.fit(inputSample, label, epochs=1000, batch_size=1, verbose=0)\n",
    "endTime = time.time()\n",
    "print(endTime - startTime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras using sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0358128547668457\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(units=32, activation='sigmoid', input_dim=32))\n",
    "model.add(Dense(units=8, activation='sigmoid'))\n",
    "model.add(Dense(units=1))\n",
    "model.compile(loss=keras.losses.mean_squared_error,\n",
    "              optimizer=keras.optimizers.SGD(lr=0.01, momentum=0.9, nesterov=True))\n",
    "startTime = time.time()\n",
    "model.fit(inputSample, label, epochs=1000, batch_size=1, verbose=0)\n",
    "endTime = time.time()\n",
    "print(endTime - startTime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
